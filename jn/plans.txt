>>>>>> You have to be very careful with confirmation bias when trying to explore and transform the same data so that it gives you what you believe, an enormous amount of confirmation bias is committed.... <<<<<<

using ml and rl is perfectly correct, you can do something personalized but in the end you fall into the same thing,

>>>>>>you just have to choose and adapt the data well,<<<<<<

if they don't use ml and rl in algorithmic trading today, 
they either have privileged information or they are real geniuses, all financial entities use ml and its variants today to make ANY investment decision

Параметры системы:

Пред подготовка данных
- объем темпа торгов #  VOL 500

Индикатор

- Период Индикатора Фишера # 10

- Параметры определения локальных минимумов и максимумов - 
    - если  идет +-+ => +++
                -+- => --- 
      Параметр последовательности   # 1

- Плотность Сигналов,
    - их частота
    - количество плохих сделок до этого момента


LSTM
- предсказать цену закрытия
- посчитать значение фишера
- определить сигнал
- соотв оценить сигнал

- проблема в том что у нас модель предсказывает на выходе одно и тоже число.





TODO:
- разобраться с JN чтобы всегда было trusted.(надоело уже один раз)
- Попробовать create_sequences но смещаться не на 1, а на размер последовательности (a.k.a 52) (see comm # 2)
- Почему кто-то передает hidden в LSTM в методе forward, а кто-то нет?
Построить распределение расстояния между сигналами, по торговым дням.

Stock price to Image
https://dwbi1.wordpress.com/2022/02/10/stock-price-forecasting-using-cnn/


 Там ошибка точно по кроссвалидации считается?
anonim040: Мне кажется кроссвалидации там не используется
anonim040: Я уже точно не помню но она же вроде на то и кроссвалидация, что она как то перекрестно должна loss считать
anonim040: А готовый cross_validate из scikitlearn не проще использовать
anonim040: просто тут обычно используют взвешенное mse чтобы вес предсказания на меньшей дистанции был больше чем на дальней


COMMENT #2
 все, я понял, но так может быть не очень круто так как у нас данные сильно зависимые
3:54anonim040: я бы каждый раз не на 1 сдвигал, а на длину последовательности, чтоб они не пересекались
3:56anonim040: я понимаю что шафл, я говорю о том что информации в модель передается не так много
3:57anonim040: речь не про последовательные, а про то что ты модель фактически 52 раза обучаешь практически на одном и том же

Comment # 3
4:35rauravanaraka: that training graph shows that it needs regularization, it is very erratic


COMMENT # 4
5:27anonim040: я надеюсь у нас модель после каждого фолда сбрасывалась?
5:27anonim040: а должна

https://github.com/devitrylouis/imaging_time_series/tree/master
