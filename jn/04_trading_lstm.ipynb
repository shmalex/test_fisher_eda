{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33c0a381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:41.966660Z",
     "start_time": "2023-11-10T12:33:41.956776Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a8b45",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/raoulma/ny-stock-price-prediction-rnn-lstm-gru/notebook\n",
    "https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f657e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:43.430643Z",
     "start_time": "2023-11-10T12:33:43.325851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>ft</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-02 22:00:38</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>14,992.25</td>\n",
       "      <td>14,986.50</td>\n",
       "      <td>14,989.50</td>\n",
       "      <td>500</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-02 22:03:41</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,992.50</td>\n",
       "      <td>14,988.25</td>\n",
       "      <td>14,990.50</td>\n",
       "      <td>500</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-02 22:08:04</td>\n",
       "      <td>14,991.00</td>\n",
       "      <td>14,992.75</td>\n",
       "      <td>14,989.50</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-02 22:13:26</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>14,995.00</td>\n",
       "      <td>14,987.75</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>500</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-02 22:14:44</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,999.00</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,997.50</td>\n",
       "      <td>500</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      open      high       low     close  vol    ft  \\\n",
       "0  2023-10-02 22:00:38 14,992.00 14,992.25 14,986.50 14,989.50  500 -0.34   \n",
       "1  2023-10-02 22:03:41 14,989.75 14,992.50 14,988.25 14,990.50  500 -0.06   \n",
       "2  2023-10-02 22:08:04 14,991.00 14,992.75 14,989.50 14,992.00  500  0.40   \n",
       "3  2023-10-02 22:13:26 14,992.00 14,995.00 14,987.75 14,989.75  500  0.20   \n",
       "4  2023-10-02 22:14:44 14,989.75 14,999.00 14,989.75 14,997.50  500  0.45   \n",
       "\n",
       "   action  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/MNQ DEC23.Last-500-Volume-Action.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e50ebec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:44.408290Z",
     "start_time": "2023-11-10T12:33:44.404467Z"
    }
   },
   "outputs": [],
   "source": [
    "import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2133bc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:45.452080Z",
     "start_time": "2023-11-10T12:33:45.447364Z"
    }
   },
   "outputs": [],
   "source": [
    "destination_folder = './model/04_trading_lstm'\n",
    "os.makedirs(destination_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4544bbd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:46.269373Z",
     "start_time": "2023-11-10T12:33:46.262384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a21e579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:47.309044Z",
     "start_time": "2023-11-10T12:33:47.298096Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scprice = scaler.fit_transform(df[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "faeaf9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:49.357153Z",
     "start_time": "2023-11-10T12:33:49.343231Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Metrics saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Metrics loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n",
    "\n",
    "def create_dataset(dataset, classes, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "            data: A numpy array of time series\n",
    "         classes: A numpy array with target variable\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback-1):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = classes[i+lookback]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90ece8ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:33:50.144094Z",
     "start_time": "2023-11-10T12:33:50.122891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>ft</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-02 22:00:38</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>14,992.25</td>\n",
       "      <td>14,986.50</td>\n",
       "      <td>14,989.50</td>\n",
       "      <td>500</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-02 22:03:41</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,992.50</td>\n",
       "      <td>14,988.25</td>\n",
       "      <td>14,990.50</td>\n",
       "      <td>500</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-02 22:08:04</td>\n",
       "      <td>14,991.00</td>\n",
       "      <td>14,992.75</td>\n",
       "      <td>14,989.50</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-02 22:13:26</td>\n",
       "      <td>14,992.00</td>\n",
       "      <td>14,995.00</td>\n",
       "      <td>14,987.75</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>500</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-02 22:14:44</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,999.00</td>\n",
       "      <td>14,989.75</td>\n",
       "      <td>14,997.50</td>\n",
       "      <td>500</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61828</th>\n",
       "      <td>2023-11-01 20:45:32</td>\n",
       "      <td>14,757.25</td>\n",
       "      <td>14,758.75</td>\n",
       "      <td>14,754.00</td>\n",
       "      <td>14,756.75</td>\n",
       "      <td>500</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61829</th>\n",
       "      <td>2023-11-01 20:48:32</td>\n",
       "      <td>14,756.75</td>\n",
       "      <td>14,759.00</td>\n",
       "      <td>14,753.75</td>\n",
       "      <td>14,754.50</td>\n",
       "      <td>500</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61830</th>\n",
       "      <td>2023-11-01 20:53:23</td>\n",
       "      <td>14,754.50</td>\n",
       "      <td>14,757.00</td>\n",
       "      <td>14,753.00</td>\n",
       "      <td>14,756.00</td>\n",
       "      <td>500</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61831</th>\n",
       "      <td>2023-11-01 20:56:02</td>\n",
       "      <td>14,756.25</td>\n",
       "      <td>14,760.00</td>\n",
       "      <td>14,753.25</td>\n",
       "      <td>14,755.75</td>\n",
       "      <td>500</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61832</th>\n",
       "      <td>2023-11-01 20:59:38</td>\n",
       "      <td>14,755.75</td>\n",
       "      <td>14,760.00</td>\n",
       "      <td>14,753.00</td>\n",
       "      <td>14,760.00</td>\n",
       "      <td>500</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61833 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      open      high       low     close  vol    ft  \\\n",
       "0      2023-10-02 22:00:38 14,992.00 14,992.25 14,986.50 14,989.50  500 -0.34   \n",
       "1      2023-10-02 22:03:41 14,989.75 14,992.50 14,988.25 14,990.50  500 -0.06   \n",
       "2      2023-10-02 22:08:04 14,991.00 14,992.75 14,989.50 14,992.00  500  0.40   \n",
       "3      2023-10-02 22:13:26 14,992.00 14,995.00 14,987.75 14,989.75  500  0.20   \n",
       "4      2023-10-02 22:14:44 14,989.75 14,999.00 14,989.75 14,997.50  500  0.45   \n",
       "...                    ...       ...       ...       ...       ...  ...   ...   \n",
       "61828  2023-11-01 20:45:32 14,757.25 14,758.75 14,754.00 14,756.75  500  2.86   \n",
       "61829  2023-11-01 20:48:32 14,756.75 14,759.00 14,753.75 14,754.50  500  2.63   \n",
       "61830  2023-11-01 20:53:23 14,754.50 14,757.00 14,753.00 14,756.00  500  2.53   \n",
       "61831  2023-11-01 20:56:02 14,756.25 14,760.00 14,753.25 14,755.75  500  2.45   \n",
       "61832  2023-11-01 20:59:38 14,755.75 14,760.00 14,753.00 14,760.00  500  2.62   \n",
       "\n",
       "       action  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "61828       0  \n",
       "61829       0  \n",
       "61830      -1  \n",
       "61831       0  \n",
       "61832       0  \n",
       "\n",
       "[61833 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa413c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:35:12.343919Z",
     "start_time": "2023-11-10T12:35:12.333868Z"
    }
   },
   "outputs": [],
   "source": [
    "lookback = 52\n",
    "test_size = 2000\n",
    "\n",
    "ts_price = df[['close']].values.astype('float32')\n",
    "ts_target = df[['action']].values.astype('float32')\n",
    "\n",
    "train_size = int(len(ts_price) * 0.67)\n",
    "test_size = len(ts_price) - train_size\n",
    "train_price, test_price = ts_price[:train_size], ts_price[train_size:]\n",
    "train_target, test_taget = ts_target[:train_size], ts_target[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0715cbc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:35:16.934218Z",
     "start_time": "2023-11-10T12:35:13.605151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41375, 52, 1]) torch.Size([41375, 1])\n",
      "torch.Size([20352, 52, 1]) torch.Size([20352, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_dataset(train_price,train_target, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test_price, test_taget, lookback=lookback)\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "# X, Y = create_dataset(dfext.price.values, dfext.target, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca583df6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:35:17.855463Z",
     "start_time": "2023-11-10T12:35:17.830991Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[14989.5000],\n",
       "         [14990.5000],\n",
       "         [14992.0000],\n",
       "         [14989.7500],\n",
       "         [14997.5000],\n",
       "         [14996.0000],\n",
       "         [15001.0000],\n",
       "         [15002.7500],\n",
       "         [15007.7500],\n",
       "         [15002.2500],\n",
       "         [14998.0000],\n",
       "         [14994.2500],\n",
       "         [14993.5000],\n",
       "         [14995.0000],\n",
       "         [14990.5000],\n",
       "         [14988.2500],\n",
       "         [14994.0000],\n",
       "         [14992.2500],\n",
       "         [14990.5000],\n",
       "         [14987.2500],\n",
       "         [14987.5000],\n",
       "         [14981.7500],\n",
       "         [14982.2500],\n",
       "         [14980.5000],\n",
       "         [14981.0000],\n",
       "         [14986.2500],\n",
       "         [14991.2500],\n",
       "         [14991.0000],\n",
       "         [14994.5000],\n",
       "         [15001.0000],\n",
       "         [14998.2500],\n",
       "         [14996.7500],\n",
       "         [14992.7500],\n",
       "         [14988.7500],\n",
       "         [14985.0000],\n",
       "         [14986.7500],\n",
       "         [14982.7500],\n",
       "         [14978.7500],\n",
       "         [14978.2500],\n",
       "         [14974.7500],\n",
       "         [14969.7500],\n",
       "         [14970.0000],\n",
       "         [14965.2500],\n",
       "         [14963.0000],\n",
       "         [14960.0000],\n",
       "         [14956.5000],\n",
       "         [14960.5000],\n",
       "         [14963.7500],\n",
       "         [14960.0000],\n",
       "         [14957.7500],\n",
       "         [14962.0000],\n",
       "         [14966.2500]], device='cuda:0'),\n",
       " tensor([[14990.5000],\n",
       "         [14992.0000],\n",
       "         [14989.7500],\n",
       "         [14997.5000],\n",
       "         [14996.0000],\n",
       "         [15001.0000],\n",
       "         [15002.7500],\n",
       "         [15007.7500],\n",
       "         [15002.2500],\n",
       "         [14998.0000],\n",
       "         [14994.2500],\n",
       "         [14993.5000],\n",
       "         [14995.0000],\n",
       "         [14990.5000],\n",
       "         [14988.2500],\n",
       "         [14994.0000],\n",
       "         [14992.2500],\n",
       "         [14990.5000],\n",
       "         [14987.2500],\n",
       "         [14987.5000],\n",
       "         [14981.7500],\n",
       "         [14982.2500],\n",
       "         [14980.5000],\n",
       "         [14981.0000],\n",
       "         [14986.2500],\n",
       "         [14991.2500],\n",
       "         [14991.0000],\n",
       "         [14994.5000],\n",
       "         [15001.0000],\n",
       "         [14998.2500],\n",
       "         [14996.7500],\n",
       "         [14992.7500],\n",
       "         [14988.7500],\n",
       "         [14985.0000],\n",
       "         [14986.7500],\n",
       "         [14982.7500],\n",
       "         [14978.7500],\n",
       "         [14978.2500],\n",
       "         [14974.7500],\n",
       "         [14969.7500],\n",
       "         [14970.0000],\n",
       "         [14965.2500],\n",
       "         [14963.0000],\n",
       "         [14960.0000],\n",
       "         [14956.5000],\n",
       "         [14960.5000],\n",
       "         [14963.7500],\n",
       "         [14960.0000],\n",
       "         [14957.7500],\n",
       "         [14962.0000],\n",
       "         [14966.2500],\n",
       "         [14963.0000]], device='cuda:0'),\n",
       " tensor([[14992.0000],\n",
       "         [14989.7500],\n",
       "         [14997.5000],\n",
       "         [14996.0000],\n",
       "         [15001.0000],\n",
       "         [15002.7500],\n",
       "         [15007.7500],\n",
       "         [15002.2500],\n",
       "         [14998.0000],\n",
       "         [14994.2500],\n",
       "         [14993.5000],\n",
       "         [14995.0000],\n",
       "         [14990.5000],\n",
       "         [14988.2500],\n",
       "         [14994.0000],\n",
       "         [14992.2500],\n",
       "         [14990.5000],\n",
       "         [14987.2500],\n",
       "         [14987.5000],\n",
       "         [14981.7500],\n",
       "         [14982.2500],\n",
       "         [14980.5000],\n",
       "         [14981.0000],\n",
       "         [14986.2500],\n",
       "         [14991.2500],\n",
       "         [14991.0000],\n",
       "         [14994.5000],\n",
       "         [15001.0000],\n",
       "         [14998.2500],\n",
       "         [14996.7500],\n",
       "         [14992.7500],\n",
       "         [14988.7500],\n",
       "         [14985.0000],\n",
       "         [14986.7500],\n",
       "         [14982.7500],\n",
       "         [14978.7500],\n",
       "         [14978.2500],\n",
       "         [14974.7500],\n",
       "         [14969.7500],\n",
       "         [14970.0000],\n",
       "         [14965.2500],\n",
       "         [14963.0000],\n",
       "         [14960.0000],\n",
       "         [14956.5000],\n",
       "         [14960.5000],\n",
       "         [14963.7500],\n",
       "         [14960.0000],\n",
       "         [14957.7500],\n",
       "         [14962.0000],\n",
       "         [14966.2500],\n",
       "         [14963.0000],\n",
       "         [14962.7500]], device='cuda:0'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], X_train[1],X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "956e4a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:35:39.797841Z",
     "start_time": "2023-11-10T12:35:39.792075Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=128)\n",
    "test_loader = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16c9311e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:11:38.514957Z",
     "start_time": "2023-11-09T22:11:38.500276Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinMaxClassifier(nn.Module):\n",
    "    def __init__(self, number_of_features, hidden_size, num_layers, out_size, lr):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers  = num_layers\n",
    "        self.out_size    = out_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=number_of_features, \n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            batch_first=True)\n",
    "        self.linear1 = nn.Linear(self.hidden_size, 2*self.hidden_size)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(2*self.hidden_size, self.out_size)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" That method is called during the training\n",
    "        \n",
    "        Args:\n",
    "            x: the tensor with data\n",
    "        \"\"\"\n",
    "#         print(x.shape)\n",
    "#         RuntimeError: input.size(-1) must be equal to input_size. Expected 15, got 1\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "#         print('Out LSTM', x.shape)\n",
    "        x = self.linear1(x)\n",
    "#         print('Linear1', x.shape)\n",
    "        x = self.drop(x)\n",
    "#         print('Drop', x.shape)\n",
    "        x = self.linear2(x)\n",
    "#         print('Linear2', x.shape)\n",
    "#         print('before squeeze', x.shape)\n",
    "#         x = torch.squeeze(x, 1)\n",
    "#         print('after squeeze', x.shape)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         print('sigmoid', x.shape)\n",
    "        return x[:,-1]\n",
    "\n",
    "#     def predict(self, inp):\n",
    "# #         print(inp)\n",
    "#         logits = self.forward(inp)\n",
    "# #         x, _ = self.lstm(inp)\n",
    "# #         logits = self.linear(x)\n",
    "#         # x = self.softmax(logits).detach().numpy()\n",
    "#         return np.argmax(logits)\n",
    "#     def train_step(self, X, y):\n",
    "# #         print(X, y)\n",
    "#         y_pred = self.forward(X)\n",
    "#         loss = self.loss(y_pred, y)\n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "#         self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5531d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:14:56.671280Z",
     "start_time": "2023-11-09T22:14:56.660516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxClassifier(\n",
      "  (lstm): LSTM(1, 50, num_layers=3, batch_first=True)\n",
      "  (linear1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "num_layers = 3\n",
    "out_size = 1\n",
    "lr = 0.01\n",
    "numer_of_features = 1\n",
    "model = MinMaxClassifier(numer_of_features, hidden_size, num_layers, out_size, lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e57c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T16:04:00.155507Z",
     "start_time": "2023-11-10T16:03:59.896602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 10 11:04:00 2023\r\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\r\n",
      "│ NVIDIA-SMI 525.85.12       Driver Version: 525.85.12       CUDA Version: 12.0     │\r\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\r\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\r\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\r\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\r\n",
      "│\u001b[33m   0  NVIDIA GeForce ...  Off  \u001b[0m│\u001b[33m 00000000:03:00.0  On \u001b[0m│\u001b[33m                  N/A \u001b[0m│\r\n",
      "│\u001b[33m  0%   50C    P2   123W / 300W \u001b[0m│\u001b[33m   6003MiB / 11264MiB \u001b[0m│\u001b[33m     39%      Default \u001b[0m│\r\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\r\n",
      "\u001b[1m\u001b[36m[ CPU: ████▌ 15.0%                        ]\u001b[0m  \u001b[1m( Load Average:  1.54  1.67  1.40 )\u001b[0m\r\n",
      "\u001b[1m\u001b[35m[ MEM: ████▊ 15.7%                        ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ▏ 0.0%                     ]\u001b[0m\r\n",
      "\r\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\r\n",
      "│ Processes:                                                                   │\r\n",
      "│ GPU    PID      USER  GPU-MEM %SM  %CPU  %MEM        TIME  COMMAND           │\r\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\r\n",
      "│ \u001b[33m  0\u001b[0m \u001b[2m  5561 G     gdm    57MiB   0   0.0   0.0  123.8 days  /usr/lib/xorg/X..\u001b[0m │\r\n",
      "│ \u001b[33m  0\u001b[0m \u001b[2m  6794 G     gdm   134MiB   0   0.0   0.4  123.8 days  /usr/bin/gnome-..\u001b[0m │\r\n",
      "│ \u001b[33m  0\u001b[0m   6169 G shmalex    11MiB   0   0.0   0.3   51.1 days  /opt/teamviewer.. │\r\n",
      "│ \u001b[33m  0\u001b[0m   8496 G shmalex   167MiB   0   0.0   0.1  123.8 days  /usr/lib/xorg/X.. │\r\n",
      "│ \u001b[33m  0\u001b[0m   8643 G shmalex    43MiB   2   0.0   0.6  123.8 days  /usr/bin/gnome-.. │\r\n",
      "│ \u001b[33m  0\u001b[0m  14105 G shmalex    73MiB   1   0.0   0.3     5:51:58  obs               │\r\n",
      "│ \u001b[33m  0\u001b[0m  14376 G shmalex    11MiB   0   0.0   0.2     5:51:17  /opt/google/chr.. │\r\n",
      "│ \u001b[33m  0\u001b[0m  21719 G shmalex     8MiB   0   0.0   0.1     4:04:57  /home/shmalex/... │\r\n",
      "│ \u001b[33m  0\u001b[0m  21784 G shmalex    10MiB   0   0.0   0.1     4:04:51  /home/shmalex/... │\r\n",
      "│ \u001b[33m  0\u001b[0m  28266 C shmalex  5220MiB  36 117.7   2.1     1:32:09  /home/shmalex/... │\r\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\r\n"
     ]
    }
   ],
   "source": [
    "!nvitop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "190fe059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:32:51.382850Z",
     "start_time": "2023-11-09T22:14:57.671171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f335e7841cc405686f499a47cbc9eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/2000], Step [1000/42000], Train Loss: nan, Valid Loss: 0.3200\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [96/2000], Step [2000/42000], Train Loss: nan, Valid Loss: 0.3437\n",
      "Epoch [143/2000], Step [3000/42000], Train Loss: nan, Valid Loss: 0.3459\n",
      "Epoch [191/2000], Step [4000/42000], Train Loss: nan, Valid Loss: 0.3459\n",
      "Epoch [239/2000], Step [5000/42000], Train Loss: nan, Valid Loss: 0.5564\n",
      "Epoch [286/2000], Step [6000/42000], Train Loss: 0.5659, Valid Loss: 0.5564\n",
      "Epoch [334/2000], Step [7000/42000], Train Loss: 0.5657, Valid Loss: 0.5562\n",
      "Epoch [381/2000], Step [8000/42000], Train Loss: 0.5657, Valid Loss: 0.5559\n",
      "Epoch [429/2000], Step [9000/42000], Train Loss: 0.5653, Valid Loss: 0.5553\n",
      "Epoch [477/2000], Step [10000/42000], Train Loss: 0.5644, Valid Loss: 0.5542\n",
      "Epoch [524/2000], Step [11000/42000], Train Loss: 0.5629, Valid Loss: 0.5524\n",
      "Epoch [572/2000], Step [12000/42000], Train Loss: 0.5605, Valid Loss: 0.5494\n",
      "Epoch [620/2000], Step [13000/42000], Train Loss: 0.5563, Valid Loss: 0.5446\n",
      "Epoch [667/2000], Step [14000/42000], Train Loss: 0.5500, Valid Loss: 0.5371\n",
      "Epoch [715/2000], Step [15000/42000], Train Loss: 0.5402, Valid Loss: 0.5255\n",
      "Epoch [762/2000], Step [16000/42000], Train Loss: 0.5256, Valid Loss: 0.5085\n",
      "Epoch [810/2000], Step [17000/42000], Train Loss: 0.5048, Valid Loss: 0.4847\n",
      "Epoch [858/2000], Step [18000/42000], Train Loss: 0.4765, Valid Loss: 0.4535\n",
      "Epoch [905/2000], Step [19000/42000], Train Loss: 0.4403, Valid Loss: 0.4149\n",
      "Epoch [953/2000], Step [20000/42000], Train Loss: 0.3977, Valid Loss: 0.3699\n",
      "Epoch [1000/2000], Step [21000/42000], Train Loss: nan, Valid Loss: 0.2256\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1048/2000], Step [22000/42000], Train Loss: 0.2270, Valid Loss: 0.2256\n",
      "Epoch [1096/2000], Step [23000/42000], Train Loss: 0.2269, Valid Loss: 0.2257\n",
      "Epoch [1143/2000], Step [24000/42000], Train Loss: 0.2271, Valid Loss: 0.2257\n",
      "Epoch [1191/2000], Step [25000/42000], Train Loss: 0.2271, Valid Loss: 0.2257\n",
      "Epoch [1239/2000], Step [26000/42000], Train Loss: 0.2271, Valid Loss: 0.2257\n",
      "Epoch [1286/2000], Step [27000/42000], Train Loss: 0.2272, Valid Loss: 0.2256\n",
      "Epoch [1334/2000], Step [28000/42000], Train Loss: 0.2270, Valid Loss: 0.2256\n",
      "Epoch [1381/2000], Step [29000/42000], Train Loss: 0.2270, Valid Loss: 0.2257\n",
      "Epoch [1429/2000], Step [30000/42000], Train Loss: 0.2269, Valid Loss: 0.2256\n",
      "Epoch [1477/2000], Step [31000/42000], Train Loss: 0.2272, Valid Loss: 0.2256\n",
      "Epoch [1524/2000], Step [32000/42000], Train Loss: 0.2267, Valid Loss: 0.2256\n",
      "Epoch [1572/2000], Step [33000/42000], Train Loss: 0.2267, Valid Loss: 0.2256\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1620/2000], Step [34000/42000], Train Loss: 0.2272, Valid Loss: 0.2256\n",
      "Epoch [1667/2000], Step [35000/42000], Train Loss: 0.2267, Valid Loss: 0.2256\n",
      "Epoch [1715/2000], Step [36000/42000], Train Loss: 0.2269, Valid Loss: 0.2256\n",
      "Epoch [1762/2000], Step [37000/42000], Train Loss: 0.2265, Valid Loss: 0.2253\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1810/2000], Step [38000/42000], Train Loss: 0.2264, Valid Loss: 0.2251\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1858/2000], Step [39000/42000], Train Loss: 0.2259, Valid Loss: 0.2247\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1905/2000], Step [40000/42000], Train Loss: 0.2254, Valid Loss: 0.2239\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [1953/2000], Step [41000/42000], Train Loss: 0.2245, Valid Loss: 0.2226\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Epoch [2000/2000], Step [42000/42000], Train Loss: 0.2230, Valid Loss: 0.2206\n",
      "Model saved to ==> ./model/04_trading_lstm/model.pt\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "\n",
      "Model saved to ==> ./model/04_trading_lstm/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "# def train(model,\n",
    "#           optimizer,\n",
    "#           lossfn = nn.BCELoss(),\n",
    "#           train_loader = train_loader,\n",
    "#           valid_loader = test_loader,\n",
    "#           num_epochs = 5,\n",
    "#           eval_every = len(train_loader) // 2,\n",
    "#           file_path = destination_folder,\n",
    "#           best_valid_loss = float(\"Inf\")):\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train(model=model, optimizer=optimizer, num_epochs=10)\n",
    "lossfn = nn.BCELoss()\n",
    "train_loader = train_loader\n",
    "valid_loader = test_loader\n",
    "num_epochs = n_epochs\n",
    "eval_every_step = 1000\n",
    "file_path = destination_folder\n",
    "best_valid_loss = float(\"Inf\")\n",
    "\n",
    "# initialize running values\n",
    "running_loss = 0.0\n",
    "valid_running_loss = 0.0\n",
    "global_step = 0\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "global_steps_list = []\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for epoch in tqdm.notebook.tqdm_notebook(range(n_epochs)):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "#         print(\"X\",len(X_batch), X_batch.shape)\n",
    "        y_pred = model(X_batch)\n",
    "        # 64 torch.Size([64, 1])\n",
    "#         print(\"y_train\", len(y_batch), y_batch.shape)\n",
    "        # 64 torch.Size([64, 15, 1])\n",
    "#         print(\"y_pred\",len(y_pred), y_pred.shape)\n",
    "#         print(y_pred)\n",
    "        loss = lossfn(y_pred, y_batch) #< \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update running values\n",
    "        running_loss += loss.item()\n",
    "        global_step += 1\n",
    "#         print(global_step, (global_step % eval_every_step)==0)\n",
    "        # evaluation step\n",
    "        if (global_step % eval_every_step) == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():                    \n",
    "                # validation loop\n",
    "\n",
    "    #                     for (labels, (title, title_len), (text, text_len), (titletext, titletext_len)), _ in valid_loader:\n",
    "                for X_batch, y_batch in valid_loader:\n",
    "                    y_pred = model(X_batch)\n",
    "                    loss = lossfn(y_pred, y_batch)\n",
    "                    valid_running_loss += loss.item()\n",
    "\n",
    "            # evaluation\n",
    "            average_train_loss = running_loss / eval_every_step\n",
    "            average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "            train_loss_list.append(average_train_loss)\n",
    "            valid_loss_list.append(average_valid_loss)\n",
    "            global_steps_list.append(global_step)\n",
    "\n",
    "            # resetting running values\n",
    "            running_loss = 0.0                \n",
    "            valid_running_loss = 0.0\n",
    "            model.train()\n",
    "\n",
    "            # print progress\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                          average_train_loss, average_valid_loss))\n",
    "\n",
    "            # checkpoint\n",
    "            if best_valid_loss > average_valid_loss:\n",
    "                best_valid_loss = average_valid_loss\n",
    "                save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "\n",
    "save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "print('Finished Training!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dd3d55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:34:28.368134Z",
     "start_time": "2023-11-09T22:34:28.361710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_steps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73293322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:33:40.324772Z",
     "start_time": "2023-11-09T22:33:40.144614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== ./model/04_trading_lstm/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU5Z348c+3u+cemOGY4ZjhBrmUc0QNHuCJmhXImgC5MCZriHGNPzcxajaJyeZy42Zdj6xxEzVmY4hJFoOKB17BKwoIilxy6zicg8wMMGf39/dH1cz0DD3DIF1d3T3f9+vVqaqnqrq/XZj59vM8Vc8jqooxxhjTXsDvAIwxxiQnSxDGGGNisgRhjDEmJksQxhhjYrIEYYwxJqaQ3wHEU9++fXXo0KF+h2GMMSlj9erVB1S1KNa+tEoQQ4cOZdWqVX6HYYwxKUNEdnW0z5qYjDHGxGQJwhhjTEyWIIwxxsSUVn0QxhhzIhobGykvL6eurs7vUDyXnZ1NaWkpGRkZXT7HEoQxptsqLy+nR48eDB06FBHxOxzPqCqVlZWUl5czbNiwLp9nTUzGmG6rrq6OPn36pHVyABAR+vTpc8I1JUsQxphuLd2TQ7OP8z2tiSlJPfTqDj462kgoIASDQlCEYECc7YAQCAiC8w/e/O8uUeuhQIDMUICMYIAsd+lsCzmZQQpzMinMzSA7I+jPFzTGJD1LEEnqd3/fxbb9Rzz/nKxQgMLcDApzMinIzaAwJ4N+PbMZUJhNSWEOAwpyGFCQTf+CbDKCVuE0Jp4qKyu54IILANizZw/BYJCiIueh5jfffJPMzMwOz121ahUPP/wwd911l2fxWYJIUs//ywxUlXBEaYo4y7Aq4bCzHXEnemqe70nRqHVoCkdoDEeob4rQGFYampzthqYIRxvCVNU2cqi2gaqjjc76UWd7V+VR3thxkKraxjbxiEBRfhZD++YxbkBPxg/sybiBPRlV3IPMkCUOYz6OPn36sHbtWgBuu+028vPz+eY3v9myv6mpiVAo9p/psrIyysrKPI3PEkQSExFCQSHkQyvQkfomdlfVUnGormVZcaiWbfsP88eVH1DbGAYgMxhgVL98xg3oyWmlBcwcXcyg3rmJD9iYNHHVVVfRu3dv1qxZw5QpU5g3bx433HADtbW15OTk8OCDDzJ69Gheeukl7rjjDp544gluu+023n//fbZv387777/PDTfcwPXXX3/SsViCMDHlZYUYWdyDkcU9jtkXjig7K4+wvqKa9RVVbKio5oVN+/jT6nJgPaeW9OTSUwdwyfj+jCzOT3zwxnwMP3h8PRsqquP6nuMG9uT7/zD+hM977733eO655wgGg1RXV7NixQpCoRDPPfcct956K3/5y1+OOWfTpk28+OKL1NTUMHr0aL72ta+d0DMPsViC8FPtR9BUDxJwXojTltO8LQEIBEGC7jLQ2gvto2BAGFGUz4iifK6YOBBw7rPeVXmUZ9bv4en1e/j5M5v5+TObGVWcz6xT+zPr1P6MG9Cz29wxYszJ+PSnP00w6DQdVFVVsXDhQrZs2YKI0NjYGPOcyy+/nKysLLKysiguLmbv3r2UlpaeVByWIPyyZx3cdw5Oj8EJkICbMEIQzIRgBoSynGUws7UsIxcy86Je+a3rWT0ht4/zyusLuX0ht7dz3sckIgztm8dXzxvBV88bwZ6qOidZvLuHe1/cyt0vbGXcgJ788/kjuWR8fwIBSxQmuXycX/peycvLa1n/7ne/y8yZM1myZAk7d+5kxowZMc/JyspqWQ8GgzQ1NZ10HJ4mCBGZBfwXEAR+rao/a7d/BvBXYIdb9H+q+kN3306gBggDTarqbW9Moh3cASicexP06Of0Nmskahl2lpGwsx5xy5q3w40QaYJwg/tqbF021UNjLRzeB41HoeEINByG+sPOuR3JLoC8IigcAr2Ht331GuIkoi7qX5DNwk8MZeEnhlJ5uJ6n1+/hNy/v4Gu/f4tRxflcd/5ILj9tACG7M8qYTlVVVVFSUgLAQw89lNDP9ixBiEgQuBe4CCgHVorIUlXd0O7Ql1X1kx28zUxVPeBVjL6qq3KWU74AhYMT85mqThKpq4KjlXDkABw94K5XOuuH98GhXfDOKqivijpZoGAQFI+BQWc4r5KpkHn8Duk++Vl87owhzD99ME+u2809L2zhG4vX8p/L3+PamSOZO7nEbqE1pgM33XQTCxcu5Be/+AXnn39+Qj9bVE+wiaOrbyxyFnCbql7ibt8CoKo/jTpmBvDNWAnCrUGUnUiCKCsr05SZMOj1e+GZW+HbuyCn0O9ojqXq9JEc3N76qtwGu9+GA5udYwIh6D8BBp8Jg6bB4LOgR//jvnUkojy7YS93v7CF9RXVlBTmcN35I5l/+iDrozAJtXHjRsaOHet3GAkT6/uKyOqOWmi8bGIqAT6I2i4Hzohx3Fki8jZQgZMs1rvlCjwrIgr8SlXvj/UhInINcA3A4MEJ+iUeD3VVgDj9AclIxOmXyO0Npe3+2zl6EMpXwvt/hw/egFUPwN9/6ewbMh0mLoBxsyE79ncLBIRZp/bnkvH9eGnzfu56YQu3/N86nt+4lzs+PZHC3I4fDjLGJI6XCSLWT8H21ZW3gCGqelhELgMeA0a5+6araoWIFAPLRWSTqq445g2dxHE/ODWI+IXvsboqJzkEUrBpJbc3nHKJ8wJoaoA978C2F+HtP8DS62DZt2DsJ51kMXyGcxdWOyLCzDHFzBhdxMOv7+JHT27g8rte4Z7PTmby4F4J/UrGmGN5+depHBgUtV2KU0tooarVqnrYXV8GZIhIX3e7wl3uA5YA0zyMNfHqqpxO4XQQynRqGed9C/55NXz5OZi0ALY8C//7KfjP8bD8e/DRzpiniwgLPzGUPy/6BACf+dXrPPjqDrxq/jTGdI2XCWIlMEpEholIJjAfWBp9gIj0F7fRWUSmufFUikieiPRwy/OAi4F3PYw18eqqO2yCSWkiMOh0+OR/wje3wKd/CwMmwWv3wD3T4PkfOndTxTBxUCHLrj+H804p5gePb+Da379FdV3se76NMd7zLEGoahNwHfAMsBF4VFXXi8giEVnkHnYl8K7bB3EXMF+dn439gFfc8jeBJ1X1aa9i9UU61SA6EsqC8XPgs4vhhnXO+sv/AfecDu/8qXUgqSgFuRn8zxen8p3LxvLshr188q5XePfDqhhvbozxmmd3Mfkhpe5i+u+zoXAQLPiD35Ek1vtvwFM3we61MOhMuPR2GDgp5qGrdx3kukfWUHm4gTvnT+Ky0wYkOFiT7uwups7vYkrBHtI00R1qELEMPgP+6UW44m6o3Ar3z4Cl1zvPZLQzdUhvnrz+HE4rLeCGxWt5fVtl4uM1xkMzZszgmWeeaVN25513cu2113Z4fPOP4Msuu4xDhw4dc8xtt93GHXfcEZf4LEH4pb6bJghw7tya8kWnQ/vMa2Ht7+GeMtj1+jGH9s7L5DcLyxjcJ5drfreKzXtqfAjYGG8sWLCAxYsXtylbvHgxCxYsOO65y5Yto7DQ22eoLEH4IRJxOqmT9RmIRMkphFk/gUWvOuNCPTwbNiw95rDC3Ewe+tLp5GQEuerBN9ldVetDsMbE35VXXskTTzxBfX09ADt37qSiooJHHnmEsrIyxo8fz/e///2Y5w4dOpQDB5ya949//GNGjx7NhRdeyObNm+MWnw3W54eGGkC7bw2iveIxcPWz8Id58OgX4bKfw7R/anNIaa9cHvzS6cz71d/50oMreXTRWfTMPrmhjI1p46mbnUE046n/aXDpzzrc3adPH6ZNm8bTTz/N7NmzWbx4MfPmzeOWW26hd+/ehMNhLrjgAt555x0mTJgQ8z1Wr17N4sWLWbNmDU1NTUyZMoWpU6fGJXyrQfiheRwmSxCt8vrAF5fCKbNg2TfhuR8cc5fT+IEF/Pfnp7B132G++vBq6ps6GXjQmBQR3czU3Lz06KOPMmXKFCZPnsz69evZsKH9EHatXn75ZebOnUtubi49e/bkiiuuiFtsVoPwQ507KYkliLYyc2He/8KTN8Irv4CaPXDFXW2GIT9nVBH/fuUEbnz0bb71p3e4c94kGzrcxEcnv/S9NGfOHG688Ubeeustamtr6dWrF3fccQcrV66kV69eXHXVVdTV1XX6Hl6NYWY1CD+01CC6eR9ELMEQ/MN/wYxb4e1H4JF5xzxY96kppdw0azRL367g9qc3+RSoMfGRn5/PjBkzuPrqq1mwYAHV1dXk5eVRUFDA3r17eeqppzo9/9xzz2XJkiXU1tZSU1PD448/HrfYrAbhB2ti6pwIzPi2MzLsE/8PHrocPvdnyC9qOeRr541g96E6frViOwMKsrlq+jAfAzbm5CxYsIBPfepTLF68mDFjxjB58mTGjx/P8OHDmT59eqfnNs9bPWnSJIYMGcI555wTt7jsQTk/rP0DPLYIrl/jTMZjOrb5afjTVTBwMix83KlhuMIR5au/W81Lm/ex7BvncEq/Y+fPNqYz9qCcPSiXfOqb+yCScB6IZDN6ltMP8f5r8MIP2+wKBoR/v3IC+dkhvrNkHZFI+vzYMSYZWILwQ3MTU5b94u2SCZ+Bsqvh1f+CTcva7Oqdl8mtl41l5c6PeHTVBx28gTHm47AE4Ye6KsjIa3N3jjmOS34KAyY6TXMHd7TZ9emppUwb1pufPrWJA4frfQrQpKp0ambvzMf5npYg/FB3yDqoT1RGNnzmYWf9TwuhsfW2PxHhJ3NP5WhDEz9+cqNPAZpUlJ2dTWVlZdonCVWlsrKS7OzsEzrP7mLyQ3cdqO9k9RoKc+6DxQvg6ZvhH+5s2TWyuAeLzhvB3S9s5cqppUwf2de/OE3KKC0tpby8nP379/sdiueys7MpLS09oXMsQfghXScLSoQxl8H0G+DVO2HwWTBxXsuur88cyeNvV/Cvj73LU984h+yMY6c5NSZaRkYGw4bZLdIdsSYmP1gN4uSc/10YMh2euAH2tTYpZWcE+dGc09hx4Ai/fGmbjwEakx4sQfjBEsTJCYbgygcgMx/++AWobx0C/OxRfZkzaSD//dJWtu6LPbWpMaZrLEH4wRLEyevR30kSB7fBEze22fWdy8eRkxHkO0vWpX3nozFesgSRaKrOg3LdfS6IeBh2Dpz7LVj3aJvJhop6ZHHLZWN5Y8dB/ry63McAjUltliASrfEoRJqsBhEv02+AHgNg+XfbDA8+r2wQZUN68ZNlGzl4pMHHAI1JXZ4mCBGZJSKbRWSriNwcY/8MEakSkbXu63tdPTdl2UB98ZWZCzNvhfKVsLF1FMtAQPjR3FM5VNvIA6/s6OQNjDEd8SxBiEgQuBe4FBgHLBCRcTEOfVlVJ7mvH57guanHEkT8TfwsFI2B526DcGNL8Zj+Pbl4XD9+9/ddHKlv8i8+Y1KUlzWIacBWVd2uqg3AYmB2As5NbjZZUPwFQ3DhD5wO67d+22bXV88bQVVtI39caeM0GXOivEwQJUD0/yvL3bL2zhKRt0XkKREZf4LnIiLXiMgqEVmVEk9DWg3CG6dc4jwb8dLP2tz2OmVwL04f2ovfvLKDxnDExwCNST1eJohYc+C1v+fwLWCIqk4E7gYeO4FznULV+1W1TFXLioqKYh2SXCxBeEMELvohHNkPr93TZtdXzx3Bh4dqWbZut0/BGZOavEwQ5cCgqO1SoCL6AFWtVtXD7voyIENE+nbl3JRVd8hZWoKIv9IyGDcHXrsbava2FJ8/ppgRRXn86m/b7bkIY06AlwliJTBKRIaJSCYwH1gafYCI9Bd3tm0RmebGU9mVc1NW82RB9hyENy74HoTr4W+tE9AHAsI15w5nw+5qXt1a6WNwxqQWzxKEqjYB1wHPABuBR1V1vYgsEpFF7mFXAu+KyNvAXcB8dcQ816tYE6quCoJZzvDVJv76jHAmF1r9WziwpaV4zuQSinpk8asVNkaTMV3l6XMQqrpMVU9R1RGq+mO37D5Vvc9dv0dVx6vqRFU9U1Vf6+zctGDDbHjv3JsgI8e57dWVFQrypelDeXnLAdZXVPkXmzEpxJ6kTjRLEN7LL4Lp34BNT8D7b7QUf+6MIeRlBvmfFdt9DM6Y1GEJItHqqi1BJMJZX4f8fm2G4CjIyWDBtME8/s5uyj866nOAxiQ/SxCJVldlkwUlQmYezLgFPngDtixvKb767GEI8MArO30LzZhUYQki0ayJKXEmfx7y+8Ob97cUDSzM4R8mDmTxyvepOtrYycnGGEsQiWYJInGCGTD1Ktj6HBxs7Xe45tzhHG0I879v7PIvNmNSgCWIRLMEkVhTF4IEYNWDLUVjB/Tk3FOKePDVndQ1hn0MzpjkZgkikRrrnIe47CG5xOk5EMZ+Etb8DhprW4oXnTucA4frWbLmQx+DMya5WYJIpHobydUXp38Faj+C9Utais4a0YfxA3vy29d2+heXMUnOEkQitQzUV+hvHN3N0HOg7ymw8tctRSLCZ8oGsWlPDZv2VPsYnDHJyxJEItlIrv4QcWoRH66GD99qKf7khAEEA8Jja9JjHEhj4s0SRCJZgvDPxPmQkQurftNS1Cc/i3NH9WXp2g+JRGyUV2PaswSRSC0JwjqpEy67ACZ8Btb92emPcM2ZXEJFVR1v7jzoY3DGJCdLEIlkNQh/nf4VaKqDNb9vKbpoXD9yM4M8ZnczGXMMSxCJZAnCX/1Pg0FnOs1MEWf60dzMELPG9+fJdbvtmQhj2rEEkUj11RAIOW3hxh+nf8V5qnr7iy1FcyaXUFPXxEub9/kYmDHJxxJEItVVOQ/JSawpt01CjLsCcvvCytbO6k+M6EPf/Cy7m8mYdixBJJINs+G/UBZM+SK89xQc+sApCga4YuJAXti0zwbwMyaKJYhEsgSRHMq+5CxXP9RSNGfyQBrCEZa9u9ufmIxJQpYgEskmC0oOhYPhlFnw1m+hqR6A00oKGF6UZ3czGRPF0wQhIrNEZLOIbBWRmzs57nQRCYvIlVFlO0VknYisFZFVXsaZMDZZUPI4/ctwZD9sfBxwht6YO6mEN3Yc5MNDtcc52ZjuwbMEISJB4F7gUmAcsEBExnVw3O3AMzHeZqaqTlLVMq/iTChrYkoew8+HXsPaNDPNnlQCwNK11lltDHhbg5gGbFXV7araACwGZsc47p+BvwDpf49hXZUN1JcsAgGYMA92vgI1ewAY3CeXqUN6sWRNOao29IYxXiaIEuCDqO1yt6yFiJQAc4H7YpyvwLMislpErvEsykQJN0HjEatBJJPxcwCFDUtbiuZMGsh7ew+zcXeNf3EZkyS8TBCxbvZv/7PsTuDbqhrrEdbpqjoFp4nq6yJybswPEblGRFaJyKr9+/efXMReap4LwiYLSh7FY6FobJt5Ii6fMJBQQPjrWuusNsbLBFEODIraLgXaN+6WAYtFZCdwJfBLEZkDoKoV7nIfsASnyeoYqnq/qpapallRUVF8v0E81R1yllaDSC7j58L7r0O1859m77xMzjuliL+urSBsI7yabs7LBLESGCUiw0QkE5gPLI0+QFWHqepQVR0K/Bm4VlUfE5E8EekBICJ5wMXAux7G6j0bhyk5jZ/LMc1Mk0vYU13HGzsq/YvLmCTgWYJQ1SbgOpy7kzYCj6rqehFZJCKLjnN6P+AVEXkbeBN4UlWf9irWhLAEkZyKToF+p7ZpZrpwbD/ys0L2TITp9kJevrmqLgOWtSuL1SGNql4Vtb4dmOhlbAlX1zwftfVBJJ3xc+CFH0HVh1BQQk5mkEvG9+epdXv44exTyc4I+h2hMb6wJ6kTxWoQyWvcXGe54a8tRVdMGkhNfROvbj3gU1DG+M8SRKJYgkhefUc6c0VENTOdNbwP+Vkhntu418fAjPGXJYhEqasCBDJ7+B2JiWX8XCh/s2WE18xQgPNGF/Hcxn02X7XptixBJEp9tdP/ELBLnpTGzXGWUc1MF43tx/6aet75sMqnoIzxl/21SpS6Ksiy5qWk1WcEDJjYpplpxugiggHhuQ3WzGS6J0sQiWID9SW/8XPhw1Xw0S4ACnMzKRvSy/ohTLdlCSJRLEEkv1jNTOP6sWlPDR8cPOpTUMb4xxJEothkQcmv9zAYOLlNM9MFY/sBWC3CdEuWIBLFJgtKDePnQsVbcHAHAMP65jGyON8ShOmWLEEkijUxpYaWZqbHWoouHNuPN7YfpKq20aegjPGHJYhEiETc21wtQSS9XkOgZGqbZqaLxhXTFFH+9l4SDydvjAcsQSRCQw2gliBSxfi5sPttqNwGwKRBveiTl2m3u5puxxJEIjQPs2GTBaWGce7MuG4zUzAgnD+mmBc376MxHPExMGMSyxJEItg4TKmlcDCUnt52CPBx/aipa2LljoM+BmZMYlmCSARLEKln/FzYs66lmemcUX3JDAVYbnczmW7EEkQitMwFYQkiZYy+zFluWQ5AbmaIs0f25bmNe1G1wftM92AJIhFaahDWB5Eyeg+DPqNgy7MtRReMLeaDg7Vs2XfYx8CMSRxLEInQkiAK/Y3DnJhRF8POV6DBGWbjgjHOU9XL7W4m001YgkgEu4spNY26EML1sPNlAPoXZDOhtMCeqjbdRpcShIjkiUjAXT9FRK4QkQxvQ0sjdVWQmQ9BT6cAN/E2ZDpk5LZpZrpwbD/WfnCIfTV1PgZmTGJ0tQaxAsgWkRLgeeBLwEPHO0lEZonIZhHZKiI3d3Lc6SISFpErT/TclFBfZbWHVBTKguEznAThdkxfOLYfqvDipn2+hmZMInQ1QYiqHgU+BdytqnOBcZ2eIBIE7gUudY9dICLHnOMedzvwzImemzJsHKbUNeoiOPQ+HHgPgLEDelBSmMPyDZYgTPrrcoIQkbOAzwFPumXHay+ZBmxV1e2q2gAsBmbHOO6fgb8A+z7GuanBEkTqGnmRs3RvdxURLhxbzCtb91PbEPYxMGO819UEcQNwC7BEVdeLyHDgxeOcUwJ8ELVd7pa1cJus5gL3nei5Ue9xjYisEpFV+/cn6WBqliBSV+EgKBrbth9iXD/qGiO8uvWAj4EZ470uJQhV/ZuqXqGqt7ud1QdU9frjnCax3qrd9p3At1W1/U+xrpzbHNv9qlqmqmVFRUXHCcknNllQaht1Eex6DeprADhjWB/ys0J2N5NJe129i+kREekpInnABmCziHzrOKeVA4OitkuBinbHlAGLRWQncCXwSxGZ08VzU4dNFpTaRl0MkUbYsQKAzFCAO+dN4mszRvgcmDHe6moT0zhVrQbmAMuAwcAXjnPOSmCUiAwTkUxgPrA0+gBVHaaqQ1V1KPBn4FpVfawr56YMVWtiSnWDz4TMHsc0Mw3pk+djUMZ4r6s35me4zz3MAe5R1UYR6XRAGlVtEpHrcO5OCgIPuP0Xi9z97fsdjntuF2NNLg1HQMOWIFJZMANGzHA6qlVBYrWAGpN+upogfgXsBN4GVojIEKD6eCep6jKcGkd0WczEoKpXHe/clFRvA/WlhVEXw8bHYd8G6Dfe72iMSYiudlLfpaolqnqZOnYBMz2OLT3YMBvpod3trsZ0B13tpC4QkV80304qIv8BWANsV9hcEOmh5wDod5olCNOtdLWT+gGgBviM+6oGHvQqqLRiI7mmj1EXwfuvt/6bGpPmupogRqjq990nm7er6g+A4V4GljZssqD0Mepi54aDbcd7RtSY9NDVBFErImc3b4jIdKDWm5DSTN0hZ2nPQaS+0tOdRL/VmplM99DVu5gWAQ+LSPPP4I+Ahd6ElGaskzp9BEMw4ny73dV0G129i+ltVZ0ITAAmqOpk4HxPI0sXdVUQyoaMbL8jMfEw6mI4vBf2vON3JMZ47oRmlFPVaveJaoAbPYgn/dTbOExpZeSFztLuZjLdwMlMOWr1666os8mC0kp+MQycbAnCdAsnkyA6HWrDuGwcpvQz8iIofxOOHvQ7EmM81WmCEJEaEamO8aoBBiYoxtRmCSL9jLoYNALbXvA7EmM81WmCUNUeqtozxquHqnb1DqjuzRJE+imZAlkFzhwRxqSxk2liMl1RV23PQKSbQBAKSqBmj9+RGOMpSxBesxpEesorgiP7jn+cMSnMEoSXGusgXG8JIh3lF8NhSxAmvVmC8JKN5Jq+8orhyH6/ozDGU5YgvNQyWZCN5Jp28oug8SjUH/Y7EmM8YwnCSzYOU/rKK3aW1g9h0pglCC+1jORqTUxpJ99NEIetmcmkL0sQXrI+iPSVV+QsrQZh0pinCUJEZonIZhHZKiI3x9g/W0TeEZG17lSm0XNO7BSRdc37vIzTMzZZUPpqqUFYgjDpy7OnoUUkCNwLXASUAytFZKmqbog67HlgqaqqiEwAHgXGRO2fqaoHvIrRcy01COuDSDstNQhrYjLpy8saxDRgqztFaQOwGJgdfYCqHlbV5kH/8ki3AQDrqiAQgoxcvyMx8RbMgJxeVoMwac3LBFECfBC1Xe6WtSEic0VkE/AkcHXULgWeFZHVInJNRx8iIte4zVOr9u9Psl9zzU9R28xj6Smv2PogTFrzcsC9WH8Vj6khqOoSYImInAv8G+DOyMJ0Va0QkWJguYhsUtUVMc6/H7gfoKysLDE1kIYjsH8z7N8EB7ZAuCH2cTtfsf6HdJZfbHcxmbTmZYIoBwZFbZcCFR0drKorRGSEiPRV1QOqWuGW7xORJThNVsckCM81HIWNj8O+DU5C2LcRDu1q3R8IOVOKdmTcHO9jNP7IK4Lda/2OwhjPeJkgVgKjRGQY8CEwH/hs9AEiMhLY5nZSTwEygUoRyQMCqlrjrl8M/NDDWDv22CLY8FcIZEDfUVAyFSZ/HorGQPFY6DXMmczedD9WgzBpzrO/bKraJCLXAc8AQeABVV0vIovc/fcB/wh8UUQagVpgnpss+uE0OzXH+IiqPu1VrB36YKWTHM75F5hxi9MxaUyzvCJoqIHGWsjI8TsaY+LO05++qroMWNau7L6o9duB22Octx2Y6GVsx6UKy78L+f3g7BstOZhjRT8L0WuIv7EY4wF7krojm5fB+687NYesfL+jMcmoZTwma2Yy6ckSRCzhJlj+feh7Ckz+gt/RmGSV7z4sZ89CmDRlvauxrHkYKrfA/D9YB7TpmIRE5QwAABBtSURBVI3oatKc1SDaqz8ML/4UBn8CRl/qdzQmmTUPt2F3Mpk0ZT+P23v9HucX4fxH7Alo07mMbMgqsBqESVtWg4hWsxdevQvGzYZBp/sdjUkF+UXWB2HSliWIaH/7GYTr4YLv+x2JSRU2N7VJY5Ygmu1/D1b/Fsquhj4j/I7GpAqrQZg0Zgmi2fM/cIblPvcmvyMxqcRGdDVpzBIEwK7XYdMTcPY3Wu9tN6Yr8oudYd2b6v2OxJi4swTRPKRGjwFw5tf9jsakGptZzqQxSxB1VZDVA2beCpk285s5QTY3tUlj9hxETiF8YYlTkzDmRNl4TCaNWQ2imT0UZz4OG4/JpDFLEMacDBuPyaQxSxDGnIzMXMjMt/GYTFqyBGHMycorshqESUuWIIw5WfnF1gdh0pIlCGNOVl6R3cVk0pKnCUJEZonIZhHZKiI3x9g/W0TeEZG1IrJKRM7u6rnGJA2rQZg05VmCEJEgcC9wKTAOWCAi49od9jwwUVUnAVcDvz6Bc41JDnnFUHsQwo1+R2JMXHlZg5gGbFXV7araACwGZkcfoKqHVVueUMsDtKvnGpM0mp+FOHLA3ziMiTMvE0QJ8EHUdrlb1oaIzBWRTcCTOLWILp/rnn+N2zy1av9+awc2PrBnIUya8jJBxHo0+ZjxLFR1iaqOAeYA/3Yi57rn36+qZapaVlRkI7EaH7SMx2Q/UEx68TJBlAODorZLgYqODlbVFcAIEel7ouca46uWEV2tBmHSi5cJYiUwSkSGiUgmMB9YGn2AiIwUcQZBEpEpQCZQ2ZVzjUkaNqKrSVOejeaqqk0ich3wDBAEHlDV9SKyyN1/H/CPwBdFpBGoBea5ndYxz/UqVmNOSmY+hHLsWQiTdjwd7ltVlwHL2pXdF7V+O3B7V881JimJ2NzUJi3Zk9TGxIPNTW3SkCUIY+Ihv9juYjJpxxKEMfFgI7qaNGQJwph4yC+Go5UQCfsdiTFxYwnCmHjIKwaNOEnCmDRhCcKYeLC5qU0asgRhTDzYeEwmDVmCMCYebDwmk4YsQRgTDzYek0lDliCMiYfsAghmWh+ESSuWIIyJBxH3aWprYjLpwxKEMfFi4zGZNGMJwph4sfGYTJqxBGFMvOQX2V1MJq1YgjAmXpr7ICIRvyMxJi4sQRgTL/nFoGGo/cjvSIyJC0sQxsSLPQth0owlCGPixeamNmnGEoQx8dIyHpN1VJv0YAnCmHixGoRJM54mCBGZJSKbRWSriNwcY//nROQd9/WaiEyM2rdTRNaJyFoRWeVlnMbERXYhBELWB2HSRsirNxaRIHAvcBFQDqwUkaWquiHqsB3Aear6kYhcCtwPnBG1f6aqHvAqRmPiKhBwOqrtWQiTJrysQUwDtqrqdlVtABYDs6MPUNXXVLX5nsC/A6UexmOM92xuapNGvEwQJcAHUdvlbllHvgw8FbWtwLMislpErunoJBG5RkRWiciq/fvtl5vxWX6x9UGYtOFZExMgMco05oEiM3ESxNlRxdNVtUJEioHlIrJJVVcc84aq9+M0TVFWVhbz/Y1JmLxi2LfR7yiMiQsvaxDlwKCo7VKgov1BIjIB+DUwW1VbZnxX1Qp3uQ9YgtNkZUxyyy9ybnNV+61iUp+XCWIlMEpEholIJjAfWBp9gIgMBv4P+IKqvhdVniciPZrXgYuBdz2M1Zj4yCuGcAPUHfI7EmNOmmdNTKraJCLXAc8AQeABVV0vIovc/fcB3wP6AL8UEYAmVS0D+gFL3LIQ8IiqPu1VrMbETfTc1Dm9/I3FmJPkZR8EqroMWNau7L6o9a8AX4lx3nZgYvtyY5Je9HhMRaf4G4sxJ8mepDYmnuxpapNGLEEYE082HpNJI5YgjImn3N4gAatBmLRgCcKYeAoEIbevPU1t0oIlCGPiLb/YxmMyacEShDHxZuMxmTTh6W2uxnRL+cVQuS3mrrrGML9+eTsigggIQkBABALSOjpNRJVwxFk2hZWwKpGIEmn3hHbzKeKObKMoqs6YNhF3RYFIRFvKVEFViai7jbMtImQEhGAgQEZQCAaEUDBAKOCsd6b9dxGEqK9DY1hpCkdojDjLpojSGI4QiSiZoQDZGUGyM4JkRa1nZwQIBQJR79/8Wc63jahS2ximtiHM0YbwMeuhgJCdESAnI0h2ZpCcDPeVGSQUCBBWJRyJONc5ojRFnOusqmQEA2SFAmSFnJiyMlrXQ0Fp+X6x/g2zoz4nKxRApPNrl8wsQRgTb3lFUFMBf/x865AbqoASbAoz5r19CCAoghJwl7hlzbTdcGbq/mFsXx51RNQeaf1fiS4BlUDLMYqgEmj51ObkoSi4SaT5yEC7eFtfbhJyGyQiBIggRFr2SptB2JqTY8DZcJJVRN34m69Dq4j7Hs3vF3GPUoQQSgFKYVSMoQAEA05QTQrhSOsgcK1RO0/vRl2FNp/bSJAGQhzVEIfIoIEQ9WTQSIhGDREmQIQAYYQwAcIEW5b1mkEdmdThLDWYjWRkQyiHcEYumtkTsvLJycogNzNITkaI3MwguVlBCnIyKMjJoDAns3U9N4OeORn0zA4lPNlYgjAm3kZdBNtehANb3Z/40rIMCZxf4pYhIEG05a+4+wdVpM0frOa6QfOyc8f7A6JuFogAkZbE5SyjzpXmo6M+VQIg7p9VCbjfyV2qohpx3rf5/TXc8v7CsbWdlngQVIiq+bhJA2fZGq8i7tLZBpEAgYAQkAASCLjJp/WqgVMjaK01RdCIU0bLsU7Sag5QAA03QbjeGTalqQEJ1yORBgLhhnbprosiQIP7OuIkvVrJ4Qi5HCaHas3lUCSXPZEC9tKLDdqLfVrIXnd5gAIyMrIYWJjNwMIcSnvlMLAgh5JeOQwszKGkMIdBvXNPPK7jsARhTLwNnwHXvhZzV/SfrlQg7ZZefk7zZwQ7OzAZ3jsSdl7abhkJQ6QJmuqcV2MtNNVDUy001jnLhiNQV02gvpq8umry6msorq+Cumqo/Qit2QhH97uJsJUiVGX258NwKdv2D2T9h8W8VlfMtshA9lFI77ws3vruRfH4dm1YgjDGmBMRCDovDwhAuMl50PLwHqjZAzW7kerdFB7cTmHlFsYfWM4VkaOQ6ZzTFMqjumAM6IUQ5yYoSxDGGJNMgiHoOcB5xaIK1RVw4D2o3ErowHv0bqqLe3IASxDGGJNaRKCgxHmNmOnpR9lzEMYYY2KyBGGMMSYmSxDGGGNisgRhjDEmJksQxhhjYrIEYYwxJiZLEMYYY2KyBGGMMSYmUf0YA08lKRHZD+zqYHdf4EACw0lldq26xq5T19h16hq/rtMQVS2KtSOtEkRnRGSVqpb5HUcqsGvVNXadusauU9ck43WyJiZjjDExWYIwxhgTU3dKEPf7HUAKsWvVNXadusauU9ck3XXqNn0QxhhjTkx3qkEYY4w5AZYgjDHGxNQtEoSIzBKRzSKyVURu9jueRBCRB0Rkn4i8G1XWW0SWi8gWd9krat8t7vXZLCKXRJVPFZF17r67xJ3lXUSyROSPbvkbIjI0kd8vXkRkkIi8KCIbRWS9iHzDLbdrFUVEskXkTRF5271OP3DL7TrFICJBEVkjIk+426l5nVQ1rV8485RvA4bjzOL6NjDO77gS8L3PBaYA70aV/Ttws7t+M3C7uz7OvS5ZwDD3egXdfW8CZ+FMl/sUcKlbfi1wn7s+H/ij39/5Y16nAcAUd70H8J57Pexatb1OAuS76xnAG8CZdp06vF43Ao8AT7jbKXmdfL+QCfiHOgt4Jmr7FuAWv+NK0Hcf2i5BbAYGuOsDgM2xrgnwjHvdBgCbosoXAL+KPsZdD+E8ASp+f+c4XLO/AhfZter0GuUCbwFn2HWKeX1KgeeB86MSREpep+7QxFQCfBC1Xe6WdUf9VHU3gLssdss7ukYl7nr78jbnqGoTUAX08SzyBHCr6pNxfh3btWrHbTZZC+wDlquqXafY7gRuAiJRZSl5nbpDgpAYZXZvb1sdXaPOrl1aXVcRyQf+AtygqtWdHRqjrFtcK1UNq+oknF/I00Tk1E4O75bXSUQ+CexT1dVdPSVGWdJcp+6QIMqBQVHbpUCFT7H4ba+IDABwl/vc8o6uUbm73r68zTkiEgIKgIOeRe4hEcnASQ6/V9X/c4vtWnVAVQ8BLwGzsOvU3nTgChHZCSwGzheR/yVFr1N3SBArgVEiMkxEMnE6dZb6HJNflgIL3fWFOO3tzeXz3bsjhgGjgDfdqnCNiJzp3kHxxXbnNL/XlcAL6jaKphL3e/0G2Kiqv4jaZdcqiogUiUihu54DXAhswq5TG6p6i6qWqupQnL81L6jq50nV6+R3h06COo0uw7k7ZRvwHb/jSdB3/gOwG2jE+cXxZZx2yueBLe6yd9Tx33Gvz2bcuyXc8jLgXXffPbQ+fZ8N/AnYinO3xXC/v/PHvE5n41TP3wHWuq/L7Fodc50mAGvc6/Qu8D233K5Tx9dsBq2d1Cl5nWyoDWOMMTF1hyYmY4wxH4MlCGOMMTFZgjDGGBOTJQhjjDExWYIwxhgTkyUI062ISD8ReUREtovIahF5XUTmuvtmNI++2cn5t4nIN0/wMw93UP4dd2TUd0RkrYic4ZbfICK5J/IZxnjBEoTpNtwHjh4DVqjqcFWdivMwU2nnZ3oSy1nAJ3FGkp2A8+BZ85g8N+AMiGeMryxBmO7kfKBBVe9rLlDVXap6d/sD3fH7H3N/3f9dRCZE7Z4oIi+4Y/v/k3t8vog8LyJvuWP4zz5OLAOAA6pa78ZxQFUrROR6YCDwooi86L73xW5N5y0R+ZM7bhQislNEbhdnnoY3RWSkW/5pEXlXnLkbVnz8y2W6O0sQpjsZjzNMdVf8AFjj/rq/FXg4at8E4HKcYZm/JyIDgTpgrqpOAWYC/9E8wUsHngUGich7IvJLETkPQFXvwhlzZ6aqzhSRvsC/Ahe6770KZ66BZtWqOg3nSds73bLvAZeo6kTgii5+X2OOYQnCdFsicq/7K3tljN1nA78DUNUXgD4iUuDu+6uq1qrqAeBFYBrOCJs/EZF3gOdwhmTu19Fnq+phYCpwDbAf+KOIXBXj0DNxJpV51R1qeyEwJGr/H6KWZ7nrrwIPubWbYCeXwJhOhfwOwJgEWg/8Y/OGqn7d/YW+KsaxnQ2p3H58GgU+BxQBU1W10R3NM7uzYFQ1jDMq6ksisg7nj/9DMeJYrqoLOnqb9uuqusjt8L4cWCsik1S1srNYjInFahCmO3kByBaRr0WVddQZvALnjz4iMgOnv6B5nojZ4szR3AdnQLaVOEMu73OTw0za/so/hoiMFpFRUUWTgF3ueg3O9KcAfwemR/Uv5IrIKVHnzYtavu4eM0JV31DV7+HMNhY9nLQxXWY1CNNtqKqKyBzgP0XkJpymnSPAt2McfhvwoNtkdJTW4ZXBGUHzSWAw8G9u5/LvgcdFZBXOiLCbjhNOPnC3O4R2E87InNe4++4HnhKR3W4/xFXAH0Qky93/rzijEwNkicgbOD/2mmsZP3eTj+CMHPr2cWIxJiYbzdWYFOU2Y5W5fSHGxJ01MRljjInJahDGGGNishqEMcaYmCxBGGOMickShDHGmJgsQRhjjInJEoQxxpiY/j8b0cuZmGB0+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9061caa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T14:29:51.188591Z",
     "start_time": "2023-11-10T14:29:51.131725Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cf94e2f7f263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumer_of_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            output = model(X_batch)\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(y_batch.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    \n",
    "    \n",
    "best_model = MinMaxClassifier(numer_of_features, hidden_size, num_layers, out_size, lr).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba0156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
