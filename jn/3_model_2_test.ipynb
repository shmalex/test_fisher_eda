{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:53:35.729806Z",
     "start_time": "2023-04-11T00:53:35.719553Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:53:35.972871Z",
     "start_time": "2023-04-11T00:53:35.967843Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:53:36.451845Z",
     "start_time": "2023-04-11T00:53:36.439882Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/nq5years2h.csv')\n",
    "dfext = pd.read_csv( '../data/nq_ext.csv', skiprows=2, names=['price', 'target'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:53:36.903640Z",
     "start_time": "2023-04-11T00:53:36.897848Z"
    }
   },
   "outputs": [],
   "source": [
    "llstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:54:03.734956Z",
     "start_time": "2023-04-11T00:54:03.710966Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, max_labels, seq_len=15):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.max_labels = max_labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.seq_len]\n",
    "        y = self.max_labels[idx+self.seq_len-1]\n",
    "#         print(x)\n",
    "        scaler = MinMaxScaler()\n",
    "        x = scaler.fit_transform(x.reshape((-1,1))).reshape((-1,))\n",
    "#         print('ADASDASDASD')\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "#         raise 'asd'\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:54:04.391523Z",
     "start_time": "2023-04-11T00:54:04.385977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dfext.price.values.astype('float32') # Your time series data as a numpy array or torch tensor\n",
    "max_labels = dfext.target.values.astype('float32') # Your labels for local maximum points as a numpy array or torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:54:04.681577Z",
     "start_time": "2023-04-11T00:54:04.672461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_data = TimeSeriesDataset(data[:6000], max_labels[:6000])\n",
    "test_data = TimeSeriesDataset(data[6000:], max_labels[6000:])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:54:05.072351Z",
     "start_time": "2023-04-11T00:54:05.065148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_size = 1 # NASDAQ 100 index is a univariate time series\n",
    "hidden_size = 64 # Number of hidden units in LSTM\n",
    "num_layers = 1 # Number of LSTM layers\n",
    "lstm = LSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:35:47.508784Z",
     "start_time": "2023-04-10T21:35:47.498021Z"
    }
   },
   "source": [
    "for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "    print(x_batch.tolist())\n",
    "    print(y_batch.tolist())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:56:30.264436Z",
     "start_time": "2023-04-11T00:54:06.139232Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss=0.1367, Test Loss=0.1476\n",
      "Epoch 2/50: Train Loss=0.0414, Test Loss=0.1476\n",
      "Epoch 3/50: Train Loss=0.2406, Test Loss=0.1468\n",
      "Epoch 4/50: Train Loss=0.2314, Test Loss=0.1462\n",
      "Epoch 5/50: Train Loss=0.4008, Test Loss=0.1480\n",
      "Epoch 6/50: Train Loss=0.3418, Test Loss=0.1446\n",
      "Epoch 7/50: Train Loss=0.1337, Test Loss=0.1428\n",
      "Epoch 8/50: Train Loss=0.1258, Test Loss=0.1399\n",
      "Epoch 9/50: Train Loss=0.1991, Test Loss=0.1365\n",
      "Epoch 10/50: Train Loss=0.0296, Test Loss=0.1348\n",
      "Epoch 11/50: Train Loss=0.1210, Test Loss=0.1299\n",
      "Epoch 12/50: Train Loss=0.1344, Test Loss=0.1294\n",
      "Epoch 13/50: Train Loss=0.0418, Test Loss=0.1293\n",
      "Epoch 14/50: Train Loss=0.1237, Test Loss=0.1308\n",
      "Epoch 15/50: Train Loss=0.1132, Test Loss=0.1278\n",
      "Epoch 16/50: Train Loss=0.0276, Test Loss=0.1296\n",
      "Epoch 17/50: Train Loss=0.1964, Test Loss=0.1278\n",
      "Epoch 18/50: Train Loss=0.0392, Test Loss=0.1289\n",
      "Epoch 19/50: Train Loss=0.0536, Test Loss=0.1277\n",
      "Epoch 20/50: Train Loss=0.2291, Test Loss=0.1293\n",
      "Epoch 21/50: Train Loss=0.2947, Test Loss=0.1290\n",
      "Epoch 22/50: Train Loss=0.1990, Test Loss=0.1278\n",
      "Epoch 23/50: Train Loss=0.0557, Test Loss=0.1288\n",
      "Epoch 24/50: Train Loss=0.1044, Test Loss=0.1285\n",
      "Epoch 25/50: Train Loss=0.0357, Test Loss=0.1287\n",
      "Epoch 26/50: Train Loss=0.1376, Test Loss=0.1272\n",
      "Epoch 27/50: Train Loss=0.1797, Test Loss=0.1292\n",
      "Epoch 28/50: Train Loss=0.1157, Test Loss=0.1282\n",
      "Epoch 29/50: Train Loss=0.3377, Test Loss=0.1291\n",
      "Epoch 30/50: Train Loss=0.1629, Test Loss=0.1283\n",
      "Epoch 31/50: Train Loss=0.3243, Test Loss=0.1280\n",
      "Epoch 32/50: Train Loss=0.1915, Test Loss=0.1293\n",
      "Epoch 33/50: Train Loss=0.1045, Test Loss=0.1287\n",
      "Epoch 34/50: Train Loss=0.3507, Test Loss=0.1279\n",
      "Epoch 35/50: Train Loss=0.2112, Test Loss=0.1286\n",
      "Epoch 36/50: Train Loss=0.0444, Test Loss=0.1273\n",
      "Epoch 37/50: Train Loss=0.3055, Test Loss=0.1293\n",
      "Epoch 38/50: Train Loss=0.2073, Test Loss=0.1280\n",
      "Epoch 39/50: Train Loss=0.1203, Test Loss=0.1274\n",
      "Epoch 40/50: Train Loss=0.1037, Test Loss=0.1291\n",
      "Epoch 41/50: Train Loss=0.0402, Test Loss=0.1263\n",
      "Epoch 42/50: Train Loss=0.1070, Test Loss=0.1266\n",
      "Epoch 43/50: Train Loss=0.2604, Test Loss=0.1269\n",
      "Epoch 44/50: Train Loss=0.1755, Test Loss=0.1304\n",
      "Epoch 45/50: Train Loss=0.1878, Test Loss=0.1266\n",
      "Epoch 46/50: Train Loss=0.1375, Test Loss=0.1265\n",
      "Epoch 47/50: Train Loss=0.4522, Test Loss=0.1297\n",
      "Epoch 48/50: Train Loss=0.0371, Test Loss=0.1276\n",
      "Epoch 49/50: Train Loss=0.1838, Test Loss=0.1264\n",
      "Epoch 50/50: Train Loss=0.1961, Test Loss=0.1277\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss with logits\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train()\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.unsqueeze(-1) # Add input_size dimension\n",
    "#         print(y_batch.shape)\n",
    "#         break\n",
    "        y_pred = lstm(x_batch)\n",
    "        loss = criterion(y_pred, y_batch.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.unsqueeze(-1) # Add input_size dimension\n",
    "            y_pred = lstm(x_test)\n",
    "            test_loss += criterion(y_pred, y_test.float()).item()\n",
    "        test_loss /= len(test_loader)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss={loss.item():.4f}, Test Loss={test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:56:30.271166Z",
     "start_time": "2023-04-11T00:56:30.266270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using trained model\n",
    "def predict_max(data_point, model, seq_len=15):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "#         data_point = torch.tensor(data_point).float()\n",
    "        data = torch.tensor(data_point, dtype=torch.float32)\n",
    "\n",
    "        # Add batch size and input size dimensions\n",
    "        data = data.unsqueeze(-1)\n",
    "#         print(data)\n",
    "#         return\n",
    "        # Pass the data through the model\n",
    "        out = model(data)\n",
    "\n",
    "        # Squeeze the output to remove the batch size and hidden dimensions\n",
    "        out = out.squeeze()\n",
    "\n",
    "        # Apply the sigmoid function to get a probability value between 0 and 1\n",
    "        prob = torch.sigmoid(out)\n",
    "\n",
    "        # Threshold the probability at 0.5 to get a binary prediction\n",
    "        pred = (prob >= 0.5).float()\n",
    "\n",
    "        # Convert the prediction to a Python scalar and return it\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:53:30.723910Z",
     "start_time": "2023-04-11T00:53:30.699760Z"
    }
   },
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            output = model(X_batch)\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(y_batch.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    \n",
    "    \n",
    "best_model = MinMaxClassifier(numer_of_features, hidden_size, num_layers, out_size, lr).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:56:33.434213Z",
     "start_time": "2023-04-11T00:56:33.428381Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T00:56:34.783326Z",
     "start_time": "2023-04-11T00:56:34.237425Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000        43\n",
      "           0     0.9672    1.0000    0.9833      1267\n",
      "\n",
      "    accuracy                         0.9672      1310\n",
      "   macro avg     0.4836    0.5000    0.4917      1310\n",
      "weighted avg     0.9354    0.9672    0.9510      1310\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/shmalex/.conda/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Max'), Text(0, 1.5, 'Not max')]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
    "    output = predict_max(x_batch, lstm)\n",
    "    y_pred.extend(output.tolist())\n",
    "    y_true.extend(y_batch.tolist())\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['Max', 'Not max'])\n",
    "ax.yaxis.set_ticklabels(['Max', 'Not max'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
